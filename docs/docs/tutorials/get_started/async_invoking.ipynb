{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30562e8d",
   "metadata": {},
   "source": [
    "# Improve performance with asynchronous invoking\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/datascienceworld-kan/vinagent-docs/blob/main/docs/tutorials/get_started/async_invoking.ipynb)\n",
    "\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install vinagent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc5d6a",
   "metadata": {},
   "source": [
    "## Initialize LLM and Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2e91d1",
   "metadata": {},
   "source": [
    "To use a list of default tools inside [vinagent.tools](https://github.com/datascienceworld-kan/vinagent/tree/main/vinagent/tools) you should set environment varibles inside `.env` including `TOGETHER_API_KEY` to use llm models at togetherai site and `TAVILY_API_KEY` to use tavily websearch tool at tavily site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e89a113",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile .env\n",
    "TOGETHER_API_KEY=\"Your together API key\"\n",
    "TAVILY_API_KEY=\"Your Tavily API key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4fb021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:vinagent.register.tool:Registered search_api:\n",
      "{'tool_name': 'search_api', 'arguments': {'query': {'type': 'Union[str, dict[str, str]]', 'value': '{}'}}, 'return': 'Any', 'docstring': 'Search for an answer from a query string\\n    Args:\\n        query (dict[str, str]):  The input query to search\\n    Returns:\\n        The answer from search query', 'dependencies': ['os', 'dotenv', 'tavily', 'dataclasses', 'typing'], 'module_path': 'vinagent.tools.websearch_tools', 'tool_type': 'module', 'tool_call_id': 'tool_d697f931-5c00-44cf-b2f1-f70f91cc2973'}\n",
      "INFO:vinagent.register.tool:Completed registration for module vinagent.tools.websearch_tools\n"
     ]
    }
   ],
   "source": [
    "from vinagent.agent.agent import Agent\n",
    "from langchain_together import ChatTogether\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv('.env'))\n",
    "\n",
    "# Step 1: Initialize LLM\n",
    "llm = ChatTogether(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\"\n",
    ")\n",
    "\n",
    "# Step 2: Initialize Agent\n",
    "agent = Agent(\n",
    "    description=\"You are a Weather Analyst\",\n",
    "    llm = llm,\n",
    "    skills = [\n",
    "        \"Update weather at anywhere\",\n",
    "        \"Forecast weather in the futher\",\n",
    "        \"Recommend picnic based on weather\"\n",
    "    ],\n",
    "    tools=['vinagent.tools.websearch_tools'],\n",
    "    tools_path = 'templates/tools.json', # Place to save tools. Default is 'templates/tools.json'\n",
    "    is_reset_tools = True # If True, it will reset tools every time reinitializing an agent. Default is False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382095ad",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Syntax for Async Invoke\n",
    "\n",
    "Vinagent supports both synchronous (`agent.invoke`) and asynchronous (`agent.ainvoke`) execution methods. Synchronous calls block the main thread until a response is received, whereas asynchronous calls allow the program to continue running while waiting for a response. This makes asynchronous execution especially effective for I/O-bound tasks, such as when interacting with external services like search engine, database connection, weather API, .... In real-world usage, asynchronous calls can perform up to twice as fast as their synchronous counterparts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e710df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = await agent.ainvoke(\"What is the weather in New York today?\")\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7ad0f3",
   "metadata": {},
   "source": [
    "## Latency Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49e108",
   "metadata": {},
   "source": [
    "\n",
    "This is a performance benchmarking table based on 100 requests to [meta-llama/Llama-3.3-70B-Instruct-Turbo-Free](https://api.together.ai/models/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free) on TogetherAI. It demonstrates that the latency of `ainvoke` is nearly twice as fast as `invoke`. You may get different results due to the randomness of the requests and state of LLM-provider server.\n",
    "\n",
    "| Number of requests | `ainvoke` (sec/req) | `invoke` (sec/req) |\n",
    "|--------------------|---------------------|----------------------|\n",
    "| 100                | 8.05-11.72          | 15.03-18.47          |\n",
    "\n",
    "This is code for benchmarking between two inference methods. To save cost, we only run 5 times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a3de0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vinagent.agent.agent:I'am chatting with unknown_user\n",
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:vinagent.register.tool:Completed executing module tool search_api({'query': 'New York weather today'})\n",
      "INFO:vinagent.agent.agent:I'am chatting with unknown_user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed executing module tool search_api({'query': 'New York weather today'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:vinagent.register.tool:Completed executing module tool search_api({'query': 'New York weather today'})\n",
      "INFO:vinagent.agent.agent:I'am chatting with unknown_user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed executing module tool search_api({'query': 'New York weather today'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:vinagent.register.tool:Completed executing module tool search_api({'query': 'New York weather today'})\n",
      "INFO:vinagent.agent.agent:I'am chatting with unknown_user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed executing module tool search_api({'query': 'New York weather today'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:vinagent.register.tool:Completed executing module tool search_api({'query': 'New York weather today'})\n",
      "INFO:vinagent.agent.agent:I'am chatting with unknown_user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed executing module tool search_api({'query': 'New York weather today'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:vinagent.register.tool:Completed executing module tool search_api({'query': 'New York weather today'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed executing module tool search_api({'query': 'New York weather today'})\n",
      "Average execution of asynchronous time over 5 runs: 8.93 seconds\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import asyncio\n",
    "\n",
    "async def benchmark_ainvoke():\n",
    "    message = await agent.ainvoke(\"What is the weather in New York today?\")\n",
    "    print(message.content)\n",
    "    return message\n",
    "\n",
    "def sync_wrapper():\n",
    "    asyncio.run(benchmark_ainvoke())\n",
    "    \n",
    "\n",
    "execution_time = timeit.timeit(sync_wrapper, number=5)\n",
    "print(f\"Average execution of asynchronous time over 5 runs: {execution_time / 5:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6612e12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vinagent.agent.agent:I'am chatting with unknown_user\n",
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:{'tool_name': 'search_api', 'tool_type': 'module', 'arguments': {'query': 'New York weather today'}, 'module_path': 'vinagent.tools.websearch_tools'}\n",
      "INFO:vinagent.register.tool:Completed executing module tool search_api({'query': 'New York weather today'})\n",
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:vinagent.agent.agent:I'am chatting with unknown_user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "According to the search_api tool, the current weather in New York today is 73Â°F with mist. The wind is blowing at 6 mph from the west, and the humidity level is 90%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:{'tool_name': 'search_api', 'tool_type': 'module', 'arguments': {'query': 'New York weather today'}, 'module_path': 'vinagent.tools.websearch_tools'}\n",
      "INFO:vinagent.register.tool:Completed executing module tool search_api({'query': 'New York weather today'})\n",
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:vinagent.agent.agent:I'am chatting with unknown_user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "According to the search_api tool, the current weather in New York today is misty with a temperature of 73Â°F. The winds are blowing from the west at a speed of 6 mph, and the humidity is relatively high at 90%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:{'tool_name': 'search_api', 'tool_type': 'module', 'arguments': {'query': 'New York weather today'}, 'module_path': 'vinagent.tools.websearch_tools'}\n",
      "INFO:vinagent.register.tool:Completed executing module tool search_api({'query': 'New York weather today'})\n",
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:vinagent.agent.agent:I'am chatting with unknown_user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "According to the search_api tool, the current weather in New York today is 73Â°F with mist. The wind is blowing at 6 mph from the west, and the humidity level is 90%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:{'tool_name': 'search_api', 'tool_type': 'module', 'arguments': {'query': 'New York weather today'}, 'module_path': 'vinagent.tools.websearch_tools'}\n",
      "INFO:vinagent.register.tool:Completed executing module tool search_api({'query': 'New York weather today'})\n",
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:vinagent.agent.agent:I'am chatting with unknown_user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "According to the search_api tool, the current weather in New York today is 73Â°F with mist. The wind is blowing at 6 mph from the west, and the humidity level is 90%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:{'tool_name': 'search_api', 'tool_type': 'module', 'arguments': {'query': 'New York weather today'}, 'module_path': 'vinagent.tools.websearch_tools'}\n",
      "INFO:vinagent.register.tool:Completed executing module tool search_api({'query': 'New York weather today'})\n",
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "According to the search_api tool, the current weather in New York today is mostly overcast with mist, and the temperature is 73Â°F. The wind is blowing at 6 mph from the west, and the humidity is relatively high at 90%.\n",
      "Average execution of synchronous time over 5 runs: 15.47 seconds\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "def benchmark_invoke():\n",
    "    message = agent.invoke(\"What is the weather in New York today?\")\n",
    "    print(message.content)\n",
    "\n",
    "execution_time = timeit.timeit(benchmark_invoke, number=5)\n",
    "print(f\"Average execution of synchronous time over 5 runs: {execution_time / 5:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8d7651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
