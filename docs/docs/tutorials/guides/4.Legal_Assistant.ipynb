{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a33931d",
   "metadata": {},
   "source": [
    "# Prerequisite Installation\n",
    "\n",
    "Ensure you install necessary libraries for this tutorial as following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2309cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install vinagent==0.0.4.post7 datasets==4.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2eaeca",
   "metadata": {},
   "source": [
    "# Prepare Data and Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421816c4",
   "metadata": {},
   "source": [
    "We will download a legal case example dataset from huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bdfc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"joelniklaus/legal_case_document_summarization\", split=\"test\")\n",
    "dataset.to_parquet(\"data/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f944250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "legal_case = pd.read_parquet(\"data/test.parquet\")\n",
    "legal_case.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b867d581",
   "metadata": {},
   "source": [
    "To prepare a knowledge base for legal cases. We need to transform each row into a document that comprises `judgement_case, dataset_name, and summary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0c09d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "docs = []\n",
    "for (i, doc) in legal_case.iterrows():\n",
    "    doc = Document(\n",
    "        page_content=doc['judgement'], \n",
    "        metadata={\n",
    "            \"judgement_case\": i, \n",
    "            \"dataset_name\": doc[\"dataset_name\"],\n",
    "            \"summary\": doc[\"summary\"]\n",
    "        })\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b90501",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3489cbb5",
   "metadata": {},
   "source": [
    "We will organize vector database by using VectorDatabaseFactory class. Which will chunk each document into many chunks and save into vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be420c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from aucodb.vectordb.factory import VectorDatabaseFactory\n",
    "from aucodb.vectordb.processor import DocumentProcessor\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. Initialize embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "# 2. Initialize document processor\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "doc_processor = DocumentProcessor(splitter=text_splitter)\n",
    "\n",
    "# 3. Initialize vector database factory\n",
    "db_type = \"milvus\"  # Supported types: ['chroma', 'faiss', 'milvus', 'pgvector', 'pinecone', 'qdrant', 'weaviate']\n",
    "vectordb_factory = VectorDatabaseFactory(\n",
    "    db_type=db_type,\n",
    "    embedding_model=embedding_model,\n",
    "    doc_processor=doc_processor\n",
    ")\n",
    "\n",
    "# 4. Store documents in the vector database\n",
    "vectordb_factory.store_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c2209e",
   "metadata": {},
   "source": [
    "Let's test vector database by a certain query to extract top-5 similar documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960037ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"claimed exemption from Sales Tax under article 286\"\n",
    "top_k = 5\n",
    "retrieved_docs = vectordb_factory.query(query, top_k)\n",
    "for (i, doc) in enumerate(retrieved_docs):\n",
    "    print(f\"Document {i}: {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ac0305",
   "metadata": {},
   "source": [
    "Write `semantic_search_query` to extract a list of relevant chunks based on the semantic similarity of embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99286e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "def semantic_search_query(query: str, top_k: int) -> List[Dict[str, Any]]:\n",
    "    if vectordb_factory.vectordb.vector_store is None:\n",
    "        raise ValueError(\"Vector store not initialized. Store documents first.\")\n",
    "\n",
    "    # Generate embedding for query\n",
    "    query_vector = vectordb_factory.vectordb.embedding_model.embed_query(query)\n",
    "\n",
    "    # Perform similarity search\n",
    "    results = vectordb_factory.vectordb.client.search(\n",
    "        collection_name=vectordb_factory.vectordb.collection_name,\n",
    "        data=[query_vector],\n",
    "        limit=top_k,\n",
    "        output_fields=[\"text\"],\n",
    "        search_params={\n",
    "            \"metric_type\": vectordb_factory.vectordb.metric_type\n",
    "        },  # Use consistent metric type\n",
    "    )[0]\n",
    "    returned_docs = [(doc.id, doc.distance) for doc in results]\n",
    "    return returned_docs\n",
    "\n",
    "results = semantic_search_query(query=query, top_k=5)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d70fea4",
   "metadata": {},
   "source": [
    "In other aspect, we need to consider the overlapping percentage of words between query and doc. This metric is another score to increase relevant extracted documents because the semantic similarity score usually high with long sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0193a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match_score(query, doc):\n",
    "    # Convert strings to sets of words (case-insensitive, removing punctuation)\n",
    "    query_words = set(query.lower().split())\n",
    "    doc_words = set(doc.lower().split())\n",
    "    \n",
    "    # Calculate intersection of words\n",
    "    common_words = query_words.intersection(doc_words)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if len(query_words) == 0 or len(doc_words) == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    # Calculate score: 0.5 * (|V_q ∩ V_d|/|V_q| + |V_q ∩ V_d|/|V_d|)\n",
    "    score = 0.5 * (len(common_words) / len(query_words) + len(common_words) / len(doc_words))\n",
    "    \n",
    "    return score\n",
    "\n",
    "def exact_match_search_query(query, docs, top_k: int=5):\n",
    "    # Calculate scores for all documents\n",
    "    scores = [(id_doc, exact_match_score(query, doc.page_content)) for (id_doc, doc) in enumerate(docs)]\n",
    "    \n",
    "    # Sort by score in descending order\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_scores[:min(top_k, len(docs))]\n",
    "\n",
    "exact_match_search_query(query=query, docs=docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec3568c",
   "metadata": {},
   "source": [
    "Next step, let's create the class `SearchLegalEngine` that includes these functionalities:\n",
    "\n",
    "- `_create_legal_cases_data`: Create a legal cases dataset. Each document is a legal record.\n",
    "- `_initialize_document_processor`: Create a vector factory, which initialize vector database and save a list of documents.\n",
    "- `exact_match_search_query`: Compute score based on exact matching percentage of words overlapping between query and document.\n",
    "- `semantic_search_query`: Search a list of scores based on semantic meaning.\n",
    "- `query_fusion_score`: Combine metrics of exact matching and semantic score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bd406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from typing import Literal\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "\n",
    "class SearchLegalEngine:\n",
    "    def __init__(self, \n",
    "            top_k: int=5, \n",
    "            temp_data_path: Path = Path(\"data/test.parquet\"),\n",
    "            db_type: Literal['chroma', 'faiss', 'milvus', 'pgvector', 'pinecone', 'qdrant', 'weaviate'] = \"milvus\",\n",
    "            embedding_model: str=\"BAAI/bge-small-en-v1.5\"\n",
    "        ):\n",
    "        self.top_k = top_k\n",
    "        self.embedding_model = HuggingFaceEmbeddings(model_name=embedding_model)\n",
    "        self.temp_data_path = temp_data_path\n",
    "        self.db_type = db_type\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        self.doc_processor = DocumentProcessor(splitter=self.text_splitter)\n",
    "\n",
    "    \n",
    "    def _download_legal_case(self):\n",
    "        dataset = load_dataset(\"joelniklaus/legal_case_document_summarization\", split=\"test\")\n",
    "        dataset.to_parquet(self.temp_data_path)\n",
    "        \n",
    "\n",
    "    def _create_legal_cases_data(self):\n",
    "        self._download_legal_case()\n",
    "        legal_case = pd.read_parquet(self.temp_data_path)\n",
    "\n",
    "        self.docs = []\n",
    "        for (i, doc) in legal_case.iterrows():\n",
    "            doc = Document(\n",
    "                page_content=doc['judgement'], \n",
    "                metadata={\n",
    "                    \"judgement_case\": i, \n",
    "                    \"dataset_name\": doc[\"dataset_name\"],\n",
    "                    \"summary\": doc[\"summary\"]\n",
    "                })\n",
    "            self.docs.append(doc)\n",
    "        return self.docs\n",
    "\n",
    "    def _initialize_document_processor(self):\n",
    "        self.vectordb_factory = VectorDatabaseFactory(\n",
    "            db_type=self.db_type,\n",
    "            embedding_model=self.embedding_model,\n",
    "            doc_processor=self.doc_processor\n",
    "        )\n",
    "        self._create_legal_cases_data()        \n",
    "        self.vectordb_factory.store_documents(self.docs)\n",
    "\n",
    "    def exact_match_score(self, query, doc):\n",
    "        # Convert strings to sets of words (case-insensitive, removing punctuation)\n",
    "        query_words = set(query.lower().split())\n",
    "        doc_words = set(doc.lower().split())\n",
    "        \n",
    "        # Calculate intersection of words\n",
    "        common_words = query_words.intersection(doc_words)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if len(query_words) == 0 or len(doc_words) == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        # Calculate score: 0.5 * (|V_q ∩ V_d|/|V_q| + |V_q ∩ V_d|/|V_d|)\n",
    "        score = 0.5 * (len(common_words) / len(query_words) + len(common_words) / len(doc_words))\n",
    "        \n",
    "        return score\n",
    "\n",
    "    def exact_match_search_query(self, query, docs):\n",
    "        \n",
    "        # Calculate scores for all documents\n",
    "        scores = [(id_doc, self.exact_match_score(query, doc.page_content)) for (id_doc, doc) in enumerate(docs)]\n",
    "        \n",
    "        return scores\n",
    " \n",
    "\n",
    "    def semantic_search_query(self, query: str, top_k: int=None) -> List[Dict[str, Any]]:\n",
    "        actual_top_k = top_k or self.top_k\n",
    "        if self.vectordb_factory.vectordb.vector_store is None:\n",
    "            raise ValueError(\"Vector store not initialized. Store documents first.\")\n",
    "\n",
    "        # Generate embedding for query\n",
    "        query_vector = self.vectordb_factory.vectordb.embedding_model.embed_query(query)\n",
    "\n",
    "        # Perform similarity search\n",
    "        results = self.vectordb_factory.vectordb.client.search(\n",
    "            collection_name=self.vectordb_factory.vectordb.collection_name,\n",
    "            data=[query_vector],\n",
    "            limit=actual_top_k,\n",
    "            output_fields=[\"text\"],\n",
    "            search_params={\n",
    "                \"metric_type\": self.vectordb_factory.vectordb.metric_type\n",
    "            },  # Use consistent metric type\n",
    "        )[0]\n",
    "        returned_docs = [(doc.id, doc.distance) for doc in results]\n",
    "        returned_docs = sorted([doc for doc in returned_docs], key=lambda x: x[0], reverse=False)\n",
    "        return returned_docs\n",
    "    \n",
    "    def query_fusion_score(self, query: str, top_k: int=None, threshold: float=None, w_semantic: float=0.5):\n",
    "        \"\"\"Query a list of documents based on exact matching and semantic scores. Return a list of similar documents.\n",
    "        Args:\n",
    "            query (str): The query to search for.\n",
    "            top_k (int): The number of documents to return. Defaults to self.top_k.\n",
    "            threshold (float): The minimum fusion score to return. Defaults to None.\n",
    "            w_semantic (float): The weight of the semantic score. Defaults to 0.5.\n",
    "        Returns:\n",
    "            list: A list of similar documents.\n",
    "        \"\"\"\n",
    "        exact_match_scores = self.exact_match_search_query(query=query, docs=self.docs)\n",
    "        semantic_scores = self.semantic_search_query(query=query, top_k=len(self.docs))\n",
    "        scores = [\n",
    "            (\n",
    "                id_exac, \n",
    "                { \n",
    "                    \"semantic_score\": seman_score,\n",
    "                    \"exac_score\": exac_score,\n",
    "                    \"fusion_score\":(1-w_semantic)*exac_score + w_semantic*seman_score \n",
    "                }\n",
    "            )\n",
    "            for ((id_exac, exac_score), (id_seman, seman_score)) \n",
    "                in list(zip(exact_match_scores, semantic_scores))\n",
    "        ]\n",
    "        sorted_scores = sorted(scores, key=lambda x: x[1][\"fusion_score\"], reverse=True)[:min(top_k, len(self.docs))]\n",
    "        sorted_docs = [(self.docs[i], score) for (i, score) in sorted_scores]\n",
    "        if threshold:\n",
    "            filter_docs = [doc for (doc, score) in sorted_docs if score['fusion_score'] > threshold]\n",
    "            return filter_docs\n",
    "        else:\n",
    "            return sorted_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1908997",
   "metadata": {},
   "source": [
    "Test `query_fusion_score`, which fuses between `exact match` and `semantic score`, to find a list of legal cases related to `Sales Tax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f88448",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_legal_engine = SearchLegalEngine(\n",
    "    top_k=5, \n",
    "    temp_data_path=Path(\"data/test.parquet\"),\n",
    "    db_type=\"milvus\",\n",
    "    embedding_model=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "\n",
    "search_legal_engine._initialize_document_processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23db4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"claimed exemption from Sales Tax\"\n",
    "search_legal_engine.query_fusion_score(query, top_k=5, w_semantic=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87905f0",
   "metadata": {},
   "source": [
    "Now, we need to write into the module file `vinagent/tools/legal_assistant/search_legal_cases.py`. Which will be loaded as a search tool in the next case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfb6d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /Users/phamdinhkhanh/Documents/Courses/Manus/vinagent/vinagent/tools/legal_assistant/search_legal_cases.py\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from aucodb.vectordb.factory import VectorDatabaseFactory\n",
    "from aucodb.vectordb.processor import DocumentProcessor\n",
    "from typing import Literal, Any, Dict, List\n",
    "from vinagent.register import primary_function\n",
    "\n",
    "\n",
    "class SearchLegalEngine:\n",
    "    def __init__(self, \n",
    "            top_k: int=5, \n",
    "            temp_data_path: Path = Path(\"data/test.parquet\"),\n",
    "            db_type: Literal['chroma', 'faiss', 'milvus', 'pgvector', 'pinecone', 'qdrant', 'weaviate'] = \"milvus\",\n",
    "            embedding_model: str=\"BAAI/bge-small-en-v1.5\"\n",
    "        ):\n",
    "        self.top_k = top_k\n",
    "        self.embedding_model = HuggingFaceEmbeddings(model_name=embedding_model)\n",
    "        self.temp_data_path = temp_data_path\n",
    "        self.db_type = db_type\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        self.doc_processor = DocumentProcessor(splitter=self.text_splitter)\n",
    "\n",
    "    \n",
    "    def _download_legal_case(self):\n",
    "        dataset = load_dataset(\"joelniklaus/legal_case_document_summarization\", split=\"test\")\n",
    "        dataset.to_parquet(self.temp_data_path)\n",
    "        \n",
    "\n",
    "    def _create_legal_cases_data(self):\n",
    "        self._download_legal_case()\n",
    "        legal_case = pd.read_parquet(self.temp_data_path)\n",
    "\n",
    "        self.docs = []\n",
    "        for (i, doc) in legal_case.iterrows():\n",
    "            doc = Document(\n",
    "                page_content=doc['judgement'], \n",
    "                metadata={\n",
    "                    \"judgement_case\": i, \n",
    "                    \"dataset_name\": doc[\"dataset_name\"],\n",
    "                    \"summary\": doc[\"summary\"]\n",
    "                })\n",
    "            self.docs.append(doc)\n",
    "        return self.docs\n",
    "\n",
    "\n",
    "    def _initialize_document_processor(self):\n",
    "        self.vectordb_factory = VectorDatabaseFactory(\n",
    "            db_type=self.db_type,\n",
    "            embedding_model=self.embedding_model,\n",
    "            doc_processor=self.doc_processor\n",
    "        )\n",
    "        self._create_legal_cases_data()        \n",
    "        self.vectordb_factory.store_documents(self.docs)\n",
    "\n",
    "    def exact_match_score(self, query, doc):\n",
    "        # Convert strings to sets of words (case-insensitive, removing punctuation)\n",
    "        query_words = set(query.lower().split())\n",
    "        doc_words = set(doc.lower().split())\n",
    "        \n",
    "        # Calculate intersection of words\n",
    "        common_words = query_words.intersection(doc_words)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if len(query_words) == 0 or len(doc_words) == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        # Calculate score: 0.5 * (|V_q ∩ V_d|/|V_q| + |V_q ∩ V_d|/|V_d|)\n",
    "        score = 0.5 * (len(common_words) / len(query_words) + len(common_words) / len(doc_words))\n",
    "        \n",
    "        return score\n",
    "\n",
    "    def exact_match_search_query(self, query, docs):\n",
    "        # Calculate scores for all documents\n",
    "        scores = [(id_doc, self.exact_match_score(query, doc.page_content)) for (id_doc, doc) in enumerate(docs)]\n",
    "        return scores\n",
    " \n",
    "\n",
    "    def semantic_search_query(self, query: str, top_k: int=None) -> List[Dict[str, Any]]:\n",
    "        actual_top_k = top_k or self.top_k\n",
    "        if self.vectordb_factory.vectordb.vector_store is None:\n",
    "            raise ValueError(\"Vector store not initialized. Store documents first.\")\n",
    "\n",
    "        # Generate embedding for query\n",
    "        query_vector = self.vectordb_factory.vectordb.embedding_model.embed_query(query)\n",
    "\n",
    "        # Perform similarity search\n",
    "        results = self.vectordb_factory.vectordb.client.search(\n",
    "            collection_name=self.vectordb_factory.vectordb.collection_name,\n",
    "            data=[query_vector],\n",
    "            limit=actual_top_k,\n",
    "            output_fields=[\"text\"],\n",
    "            search_params={\n",
    "                \"metric_type\": self.vectordb_factory.vectordb.metric_type\n",
    "            },  # Use consistent metric type\n",
    "        )[0]\n",
    "        returned_docs = [(doc.id, doc.distance) for doc in results]\n",
    "        returned_docs = sorted([doc for doc in returned_docs], key=lambda x: x[0], reverse=False)\n",
    "        return returned_docs\n",
    "\n",
    "    def query_fusion_score(self, query: str, top_k: int=None, threshold: float=None, w_semantic: float=0.5):\n",
    "        \"\"\"Query a list of documents based on exact matching and semantic scores. Return a list of similar documents.\n",
    "        Args:\n",
    "            query (str): The query to search for.\n",
    "            top_k (int): The number of documents to return. Defaults to self.top_k.\n",
    "            threshold (float): The minimum fusion score to return. Defaults to None.\n",
    "            w_semantic (float): The weight of the semantic score. Defaults to 0.5.\n",
    "        Returns:\n",
    "            list: A list of similar documents.\n",
    "        \"\"\"\n",
    "        exact_match_scores = self.exact_match_search_query(query=query, docs=self.docs)\n",
    "        semantic_scores = self.semantic_search_query(query=query, top_k=len(self.docs))\n",
    "        scores = [\n",
    "            (\n",
    "                id_exac, \n",
    "                { \n",
    "                    \"semantic_score\": seman_score,\n",
    "                    \"exac_score\": exac_score,\n",
    "                    \"fusion_score\":(1-w_semantic)*exac_score + w_semantic*seman_score \n",
    "                }\n",
    "            )\n",
    "            for ((id_exac, exac_score), (id_seman, seman_score)) \n",
    "                in list(zip(exact_match_scores, semantic_scores))\n",
    "        ]\n",
    "        sorted_scores = sorted(scores, key=lambda x: x[1][\"fusion_score\"], reverse=True)[:min(top_k, len(self.docs))]\n",
    "        sorted_docs = [(self.docs[i], score) for (i, score) in sorted_scores]\n",
    "        if threshold:\n",
    "            filter_docs = [doc for (doc, score) in sorted_docs if score['fusion_score'] > threshold]\n",
    "            return filter_docs\n",
    "        else:\n",
    "            return sorted_docs\n",
    "\n",
    "@primary_function\n",
    "def query_similar_legal_cases(query: str, n_legal_cases: int=2, threshold: float=0.6):\n",
    "    \"\"\"Query the similar legal cases to the given query.\n",
    "    Args:\n",
    "        query (str): The query string.\n",
    "        n_legal_cases (int): The number of legal cases\n",
    "        threshold (float): The similarity threshold. Defaults to 0.6.\n",
    "    \n",
    "    Returns:\n",
    "        The similar legal cases.\n",
    "    \"\"\"\n",
    "    search_legal_engine = SearchLegalEngine(\n",
    "        top_k=n_legal_cases, \n",
    "        temp_data_path=Path(\"data/test.parquet\"),\n",
    "        db_type=\"milvus\",\n",
    "        embedding_model=\"BAAI/bge-small-en-v1.5\"\n",
    "    )\n",
    "    search_legal_engine._create_legal_cases_data()\n",
    "    search_legal_engine._initialize_document_processor()\n",
    "    docs = search_legal_engine.query_fusion_score(query, top_k=n_legal_cases, threshold=threshold, w_semantic=0.7)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b508ae07",
   "metadata": {},
   "source": [
    "# Initialize Legal Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ee34d",
   "metadata": {},
   "source": [
    "We demonstrate how to initialize a legal assistant on vinagent, which can assist users with tasks like:\n",
    "\n",
    "- Search the relevant legal cases.\n",
    "- Summarize the major timeline of events in a certain legal case.\n",
    "- Proceed arguments analysis to define the strength and weakness of appellants' arguments.\n",
    "- Jurisdictional analysis of the Act and Regulation. \n",
    "- Analyze the ethical and bias in court ruling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vinagent.agent.agent import Agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from vinagent.agent.agent import Agent\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv('.env'))\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = \"o4-mini\"\n",
    ")\n",
    "\n",
    "legal_agent = Agent(\n",
    "    name=\"Legal Assistant\",\n",
    "    description=\"A legal assistant who can find the similar legal cases\",\n",
    "    llm = llm,\n",
    "    skills=[\n",
    "        \"search similar legal cases\",\n",
    "        \"summary the legal cases\",\n",
    "        \"extract the main entities in the legal cases\",\n",
    "        \"search information on the internet\"\n",
    "    ],\n",
    "    tools=[\n",
    "        '/Users/phamdinhkhanh/Documents/Courses/Manus/vinagent/vinagent/tools/legal_assistant/search_legal_cases.py',\n",
    "        '/Users/phamdinhkhanh/Documents/Courses/Manus/vinagent/vinagent/tools/websearch_tools.py'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f17fb8c",
   "metadata": {},
   "source": [
    "# Find the relevant legal case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a2a9c0",
   "metadata": {},
   "source": [
    "Attorney usually finds the relevant legal cases to prepare before starting a lawsuit. The primary target of finding similar legal cases is to identify relevant precedents that guide the resolution of a current case, ensuring consistency and fairness in legal outcomes. By researching cases with comparable facts or legal issues, attorneys can build stronger arguments, predict judicial rulings, and uncover defenses or counterarguments. This process supports compliance with the principle of stare decisis, enhances case strategy, and provides leverage in negotiations, ultimately saving time and resources while grounding legal decisions in established judicial authority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed894cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = legal_agent.invoke(\n",
    "    \"Let find one legal case claimed exemption sales tax\", \n",
    "    is_tool_formatted=False,\n",
    "    max_history=1\n",
    ")\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e575220",
   "metadata": {},
   "source": [
    "This is the main content of similar legal case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a50f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "message.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb250b3",
   "metadata": {},
   "source": [
    "In there, you only use `is_tool_formatted=False` to disable the next step of modifying the tool message. We set `max_history=1` to use current query and remove the history context is to ensure the context length does not exceed the maximum length of llm acceptance criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd0434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_agent.in_conversation_history.get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cefb26",
   "metadata": {},
   "source": [
    "The history only return a list of messages ending with `ToolMessage`. If you want Agent to modify the `ToolMessage` as human preference. Let's turn `is_tool_formatted=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = legal_agent.invoke(\n",
    "    \"Let find one legal case claimed exemption sales tax\", \n",
    "    is_tool_formatted=True,\n",
    "    max_history=1\n",
    ")\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a2c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_agent.in_conversation_history.get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ea7964",
   "metadata": {},
   "source": [
    "By default, Vinagent agent can store up to last 10 messages inside it's conversation history. Therefore, if we continue the query, a list of answer will append to the existing history. In this case, you accept to modify the tool result that means you will obtain `AIMessage` at the last."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aa67a9",
   "metadata": {},
   "source": [
    "# Summarize legal case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f25e4a",
   "metadata": {},
   "source": [
    "With very long legal case, we can not capture in detailed each events. Therefore we need summarize the legal case in a short form to accelerate the reading speed of attorneys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd6b375",
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_case = docs[199].page_content\n",
    "message = legal_agent.invoke(f\"Let's summarize this legal case in 200 words including context, development, plaintiff's arguments, and court ruling \\n{legal_case}\", max_history=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b8fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35533af0",
   "metadata": {},
   "source": [
    "# Timeline and Fact Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e63669",
   "metadata": {},
   "source": [
    "We can structure the timeline of events for each legal case in descending order. Thus, it will help to track the event follow better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b71552",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = legal_agent.invoke(f\"Let's create a timeline of events in this legal case in descending order: \\n{legal_case}\", max_history=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9768260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3567cfe9",
   "metadata": {},
   "source": [
    "# Argument analysis\n",
    "\n",
    "Sometimes, attorney dives deepth to understand the strength and weakness of appellants' arguments. This is to ensure they can increase the probability of win before the trial begins. legal_agent can also deeply analyze the strength and weakness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8c0c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = legal_agent.invoke(f\"Let's analyze the strengths and weaknesses of appellants' arguments: \\n{legal_case}\", max_history=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a193e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297ed892",
   "metadata": {},
   "source": [
    "# Jurisdictional Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8d8837",
   "metadata": {},
   "source": [
    "Jurisdictional analysis is vital in legal proceedings to ensure challenges are pursued correctly and efficiently. It serves to identify the correct legal framework, ensure compliance with time limits, define the scope of review, clarify court hierarchy and appeal routes, guide remedies and outcomes, and align with statutory interplay. By addressing these aspects, jurisdictional analysis prevents procedural errors, focuses arguments on permissible legal grounds, and informs strategic decisions, thereby upholding the integrity of the judicial process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c20896",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = legal_agent.invoke(f\"Let's analyze the jurisdictional analysis: \\n{legal_case}\", max_history=1)\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5544b74",
   "metadata": {},
   "source": [
    "# Ethical and Bias in court ruling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e4d991",
   "metadata": {},
   "source": [
    "Court rulings need to be ethical and free from bias to deliver fair, open, and responsible decisions, especially in tricky cases while many unfair judgements were made. It’s about ensuring justice for future generations, weighing economic gains against environmental and local community impacts, being transparent, handling scientific unknowns carefully, avoiding institutional blind spots, and striking the right balance in judicial oversight. If courts don’t tackle these ethical and bias issues head-on, they risk deepening inequalities, weakening environmental protections, and losing the public’s trust in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58221a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = legal_agent.invoke(f\"Let's consider the ethical and bias arguments of court ruling for this legal case: \\n{legal_case}\", max_history=1)\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad206f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
