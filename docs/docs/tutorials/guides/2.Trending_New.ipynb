{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e980a08",
   "metadata": {},
   "source": [
    "# Finding Trending new on Google New\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/datascienceworld-kan/vinagent-docs/blob/main/docs/tutorials/guides/2.Trending_New.ipynb)\n",
    "\n",
    "Keeping up with trending information about a specific company is crucial for investment decisions. By collecting a set of key news items in a timely manner, you can proactively mitigate risks and seize lucrative opportunities. This tutorial will guide you through designing a Trending Search Agent to collect news efficiently and on time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c19ddd",
   "metadata": {},
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f716b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install vinagent \n",
    "%pip install tavily-python=0.3.1 googlenewsdecoder=0.1.7 langchain-together=0.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a5b8dd",
   "metadata": {},
   "source": [
    "## Setup environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35bff83",
   "metadata": {},
   "source": [
    "To use a list of default tools inside [vinagent.tools](vinagent/tools/) you should set environment varibles inside `.env` including `TOGETHER_API_KEY` to use llm models at [togetherai](https://api.together.ai/signin) site and `TAVILY_API_KEY` to use tavily websearch tool at [tavily](https://app.tavily.com/home) site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b59050",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile .env\n",
    "TOGETHER_API_KEY=your_api_key\n",
    "TAVILY_API_KEY=your_tavily_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51342092",
   "metadata": {},
   "source": [
    "## Design trending tools\n",
    "\n",
    "We leverage Google News to search for a list of RSS links related to a particular topic, and then use a decoding method to parse the content of each article. An LLM is used to summarize the key points of each article and organize them into a list of trending articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266e2494",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile vinagent/tools/trending_news.py\n",
    "import logging\n",
    "import re\n",
    "from typing import Optional, Dict\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "from langchain_together import ChatTogether\n",
    "from googlenewsdecoder import gnewsdecoder\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()\n",
    "model = ChatTogether(model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\")\n",
    "\n",
    "\n",
    "class TrendingTopics:\n",
    "    def __init__(self):\n",
    "        self._news_cache = None\n",
    "        self._cache_timestamp = None\n",
    "        self._cache_duration = 300  # Cache for 5 minutes\n",
    "        self._max_text_length = 10000  # Max characters for model input\n",
    "        self._header_agent = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/91.0.4472.124\"\n",
    "        }\n",
    "\n",
    "    def _is_valid_url(self, url: str) -> bool:\n",
    "        \"\"\"Validate URL format.\n",
    "        Args:\n",
    "            url (str): input link for validating.\n",
    "        Returns:\n",
    "            bool: True if it was right link, else False.\n",
    "        \"\"\"\n",
    "        pattern = re.compile(r\"^https?://[^\\s/$.?#].[^\\s]*$\")\n",
    "        return bool(pattern.match(url))\n",
    "\n",
    "    def decode_rss_url(self, source_url: str) -> Optional[str]:\n",
    "        \"\"\"Decode Google News RSS URL.\n",
    "        Args:\n",
    "            source_url (str): Google News RSS URL.\n",
    "        Returns:\n",
    "            str: Decoded URL or None if decoding fails.\n",
    "        \"\"\"\n",
    "        if not self._is_valid_url(source_url):\n",
    "            logger.error(\"Invalid URL format: %s\", source_url)\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            decoded_url = gnewsdecoder(source_url, interval=1)\n",
    "            if decoded_url.get(\"status\"):\n",
    "                return decoded_url[\"decoded_url\"]\n",
    "            logger.warning(\"Decoding failed: %s\", decoded_url[\"message\"])\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logger.error(\"Error decoding URL %s: %s\", source_url, str(e))\n",
    "            return None\n",
    "\n",
    "    def extract_text_from_rss_url(self, rss_url: str) -> Optional[str]:\n",
    "        \"\"\"Extract cleaned text from RSS URL.\n",
    "        Args:\n",
    "            - rss_url (str): Google News RSS URL.\n",
    "        Returns:\n",
    "            str: Cleaned text from the RSS URL or None if extraction fails.\n",
    "        \"\"\"\n",
    "        if not self._is_valid_url(rss_url):\n",
    "            logger.error(\"Invalid RSS URL: %s\", rss_url)\n",
    "            return None\n",
    "\n",
    "        decoded_url = self.decode_rss_url(rss_url)\n",
    "        if not decoded_url:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            response = requests.get(decoded_url, headers=self._header_agent, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "            for elem in soup.find_all([\"script\", \"style\", \"nav\", \"footer\"]):\n",
    "                elem.decompose()\n",
    "\n",
    "            text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "            return text[: self._max_text_length]\n",
    "        except requests.RequestException as e:\n",
    "            logger.error(\"Error fetching URL %s: %s\", decoded_url, str(e))\n",
    "            return None\n",
    "\n",
    "    def summarize_article(self, title: str, source_url: str) -> Optional[str]:\n",
    "        \"\"\"Generate structured article summary.\"\"\"\n",
    "        if not title or not self._is_valid_url(source_url):\n",
    "            logger.error(\"Invalid title or URL: %s, %s\", title, source_url)\n",
    "            return None\n",
    "        decoded_url = self.decode_rss_url(source_url)\n",
    "        text_content = self.extract_text_from_rss_url(source_url)\n",
    "        if not text_content:\n",
    "            logger.warning(\"No text content extracted for %s\", decoded_url)\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            prompt = (\n",
    "                \"You are a searching assistant who are in charge of collecting the trending news.\"\n",
    "                \"Let's summarize the following crawled content by natural language, Markdown format.\"\n",
    "                f\"- The crawled content**: {text_content[:self._max_text_length]}\\n\"\n",
    "                \"Let's organize output according to the following structure:\\n\"\n",
    "                f\"# {title}\\n\"\n",
    "                \"## What is new?\"\n",
    "                \"- Summarize novel insights or findings.\\n\"\n",
    "                \"## Highlight\"\n",
    "                \"- Highlight the key points with natural language.\\n\"\n",
    "                \"## Why it matters\"\n",
    "                \"- Analyze significance and impact that are more specific and individual. Not repeat the same content with 'Hightlight' and 'What is new?' sections.\\n\"\n",
    "                \"## Link\"\n",
    "                f\"{decoded_url}\\n\\n\"\n",
    "            )\n",
    "            response = model.invoke(prompt)\n",
    "            return response.content\n",
    "        except Exception as e:\n",
    "            logger.error(\"Error summarizing article %s: %s\", title, str(e))\n",
    "            return None\n",
    "\n",
    "    def get_ai_news(\n",
    "        self,\n",
    "        top_k: int = 5,\n",
    "        topic: str = \"artificial intelligence\",\n",
    "        host_language: str = \"en-US\",\n",
    "        geo_location: str = \"US\",\n",
    "    ) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Fetch top 10 AI news articles.\n",
    "        Args:\n",
    "            - top_k: Number of articles to fetch.\n",
    "            - topic (str): Search topic. Default is \"artificial intelligence\",\n",
    "            - host_language (str): Set language of the search results. Default is \"en-US\".\n",
    "            - geo_location (str): Set location of the search results. Default is \"US\".\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing article links\n",
    "        \"\"\"\n",
    "        query = \"+\".join(topic.split())\n",
    "        url = f\"https://news.google.com/rss/search?q={query}&hl={host_language}&gl={geo_location}\"\n",
    "        try:\n",
    "            response = requests.get(url, headers=self._header_agent, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, \"xml\")\n",
    "\n",
    "            items = soup.find_all(\"item\")[:top_k]\n",
    "            news_list = [\n",
    "                {\n",
    "                    \"id\": idx,\n",
    "                    \"title\": item.title.text,\n",
    "                    \"link\": item.link.text,\n",
    "                    \"published_date\": item.pubDate.text,\n",
    "                    \"source\": item.source.text if item.source else \"Unknown\",\n",
    "                    \"summary\": \"\",\n",
    "                }\n",
    "                for idx, item in enumerate(items)\n",
    "            ]\n",
    "            self._news_cache = pd.DataFrame(news_list)\n",
    "            self._cache_timestamp = pd.Timestamp.now()\n",
    "            return self._news_cache\n",
    "        except requests.RequestException as e:\n",
    "            logger.error(\"Error fetching news: %s\", str(e))\n",
    "            return None\n",
    "\n",
    "    def get_summary(self, news_id: int) -> Dict:\n",
    "        \"\"\"Generate JSON summary for a news article.\"\"\"\n",
    "        try:\n",
    "            if not isinstance(news_id, int) or news_id < 0:\n",
    "                return {\"success\": False, \"error\": \"Invalid news ID\"}\n",
    "\n",
    "            if self._news_cache is None or self._news_cache.empty:\n",
    "                return {\"success\": False, \"error\": \"Failed to fetch news data\"}\n",
    "\n",
    "            if news_id >= len(self._news_cache):\n",
    "                return {\"success\": False, \"error\": f\"Invalid news ID: {news_id}\"}\n",
    "\n",
    "            article = self._news_cache.iloc[news_id]\n",
    "            summary = self.summarize_article(article[\"title\"], article[\"link\"])\n",
    "\n",
    "            if not summary:\n",
    "                return {\"success\": False, \"error\": \"Failed to generate summary\"}\n",
    "\n",
    "            return {\"success\": True, \"summary\": summary}\n",
    "        except Exception as e:\n",
    "            logger.error(\"Error in get_summary for ID %d: %s\", news_id, str(e))\n",
    "            return {\"success\": False, \"error\": f\"Server error: {str(e)}\"}\n",
    "\n",
    "\n",
    "def trending_news_google_tools(\n",
    "    top_k: int = 5,\n",
    "    topic: str = \"AI\",\n",
    "    host_language: str = \"en-US\",\n",
    "    geo_location: str = \"US\",\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Summarize the top trending news from Google News from a given topic.\n",
    "    Args:\n",
    "        - top_k: Number of articles to fetch.\n",
    "        - topic (str): Search topic. Default is \"artificial+intelligence\",\n",
    "        - host_language (str): Language of search results ('en-US', 'vi-VN', 'fr-FR'). Default is 'en-US'.\n",
    "        - geo_location (str): Location of search results (e.g., 'US', 'VN', 'FR'). Default is 'US'.\n",
    "    Returns:\n",
    "        a list of dictionaries containing the title, link, and summary of the top trending news.\n",
    "    \"\"\"\n",
    "    trending = TrendingTopics()\n",
    "    news_df = trending.get_ai_news(\n",
    "        top_k=top_k, topic=topic, host_language=host_language, geo_location=geo_location\n",
    "    )\n",
    "    news = []\n",
    "    if news_df is not None:\n",
    "        for i in range(len(news_df)):\n",
    "            summary_i = trending.get_summary(i)\n",
    "            logger.info(summary_i)\n",
    "            news.append(summary_i)\n",
    "    content = \"\\n\\n\".join([item[\"summary\"] for item in news if \"summary\" in item])\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f03e9",
   "metadata": {},
   "source": [
    "## Initialize your LLM and Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c3adf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:vinagent.register.tool:Registered trending_news_google_tools:\n",
      "{'tool_name': 'trending_news_google_tools', 'arguments': {'top_k': 5, 'topic': 'AI', 'host_language': 'en-US', 'geo_location': 'US'}, 'return': 'a list of dictionaries containing the title, link, and summary of the top trending news', 'docstring': 'Summarize the top trending news from Google News from a given topic.', 'dependencies': ['logging', 're', 'typing', 'requests', 'dotenv', 'pandas', 'bs4', 'urllib.parse', 'langchain_together', 'googlenewsdecoder'], 'module_path': 'vinagent.tools.trending_news', 'tool_type': 'module', 'tool_call_id': 'tool_64ac41d7-450e-4ca1-8280-9fd3c37dc40c'}\n",
      "INFO:vinagent.register.tool:Registered TrendingTopics.get_ai_news:\n",
      "{'tool_name': 'TrendingTopics.get_ai_news', 'arguments': {'top_k': 5, 'topic': 'artificial intelligence', 'host_language': 'en-US', 'geo_location': 'US'}, 'return': 'pd.DataFrame: DataFrame containing article links', 'docstring': 'Fetch top 10 AI news articles.', 'dependencies': ['logging', 're', 'typing', 'requests', 'dotenv', 'pandas', 'bs4', 'urllib.parse', 'langchain_together', 'googlenewsdecoder'], 'module_path': 'vinagent.tools.trending_news', 'tool_type': 'module', 'tool_call_id': 'tool_c0f25283-ee65-4381-a91c-63d4c62a3466'}\n",
      "INFO:vinagent.register.tool:Registered TrendingTopics.get_summary:\n",
      "{'tool_name': 'TrendingTopics.get_summary', 'arguments': {'news_id': 0}, 'return': 'Dict', 'docstring': 'Generate JSON summary for a news article.', 'dependencies': ['logging', 're', 'typing', 'requests', 'dotenv', 'pandas', 'bs4', 'urllib.parse', 'langchain_together', 'googlenewsdecoder'], 'module_path': 'vinagent.tools.trending_news', 'tool_type': 'module', 'tool_call_id': 'tool_3b64284b-e858-43f4-9fec-fc9c7d85de50'}\n",
      "INFO:vinagent.register.tool:Registered TrendingTopics.summarize_article:\n",
      "{'tool_name': 'TrendingTopics.summarize_article', 'arguments': {'title': '', 'source_url': ''}, 'return': 'Optional[str]', 'docstring': 'Generate structured article summary.', 'dependencies': ['logging', 're', 'typing', 'requests', 'dotenv', 'pandas', 'bs4', 'urllib.parse', 'langchain_together', 'googlenewsdecoder'], 'module_path': 'vinagent.tools.trending_news', 'tool_type': 'module', 'tool_call_id': 'tool_647b02a0-66ac-4b49-9764-99d42ab41f61'}\n",
      "INFO:vinagent.register.tool:Registered TrendingTopics.extract_text_from_rss_url:\n",
      "{'tool_name': 'TrendingTopics.extract_text_from_rss_url', 'arguments': {'rss_url': ''}, 'return': 'Optional[str]', 'docstring': 'Extract cleaned text from RSS URL.', 'dependencies': ['logging', 're', 'typing', 'requests', 'dotenv', 'pandas', 'bs4', 'urllib.parse', 'langchain_together', 'googlenewsdecoder'], 'module_path': 'vinagent.tools.trending_news', 'tool_type': 'module', 'tool_call_id': 'tool_c9369568-fbaa-4a7e-a3a0-739efae35cfb'}\n",
      "INFO:vinagent.register.tool:Registered TrendingTopics.decode_rss_url:\n",
      "{'tool_name': 'TrendingTopics.decode_rss_url', 'arguments': {'source_url': ''}, 'return': 'Optional[str]', 'docstring': 'Decode Google News RSS URL.', 'dependencies': ['logging', 're', 'typing', 'requests', 'dotenv', 'pandas', 'bs4', 'urllib.parse', 'langchain_together', 'googlenewsdecoder'], 'module_path': 'vinagent.tools.trending_news', 'tool_type': 'module', 'tool_call_id': 'tool_ec0cb8c7-743c-4a8c-b753-4ef0a969c4f6'}\n",
      "INFO:vinagent.register.tool:Registered TrendingTopics._is_valid_url:\n",
      "{'tool_name': 'TrendingTopics._is_valid_url', 'arguments': {'url': ''}, 'return': 'bool', 'docstring': 'Validate URL format.', 'dependencies': ['logging', 're', 'typing', 'requests', 'dotenv', 'pandas', 'bs4', 'urllib.parse', 'langchain_together', 'googlenewsdecoder'], 'module_path': 'vinagent.tools.trending_news', 'tool_type': 'module', 'tool_call_id': 'tool_fdb1acc0-0086-4ca9-af29-c122100c854a'}\n",
      "INFO:vinagent.register.tool:Completed registration for module vinagent.tools.trending_news\n"
     ]
    }
   ],
   "source": [
    "from langchain_together import ChatTogether \n",
    "from vinagent.agent.agent import Agent\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv('.env')) # Replace by your own .env absolute path file\n",
    "\n",
    "llm = ChatTogether(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\"\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    description=\"You are a Financial Analyst\",\n",
    "    llm = llm,\n",
    "    skills = [\n",
    "        \"Deeply analyzing financial markets\", \n",
    "        \"Searching information about stock price\",\n",
    "        \"Visualization about stock price\"],\n",
    "    tools = [\n",
    "        'vinagent.tools.trending_news'\n",
    "    ],\n",
    "    tools_path = 'templates/tools.json',\n",
    "    is_reset_tools = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4eb15",
   "metadata": {},
   "source": [
    "## Asking your agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2272cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = agent.invoke(\"\"\"Let's find the top 5 trending news about NVIDIA today.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb9d5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Where Will Nvidia Stock Be in 10 Years? - Yahoo Finance\n",
       "## What is new?\n",
       "Nvidia's generative AI business is still performing well, but there are signs of slowing growth. The company's revenue growth has decelerated to 69% from 262% in the previous fiscal quarter. Additionally, new technologies like self-driving cars and robotics could be key to Nvidia's long-term success, with potential annual revenue of $300 billion to $400 billion by 2035 for self-driving technology and $38 billion for humanoid robots.\n",
       "\n",
       "## Highlight\n",
       "The key points of the article include: Nvidia's data center business represents 89% of its total revenue, the company's AI chip business may be slowing down, and new business verticals like robotics and self-driving cars could help diversify Nvidia's revenue streams. The company's automation and robotics segment has already shown significant growth, with first-quarter sales jumping 72% year over year to $567 million.\n",
       "\n",
       "## Why it matters\n",
       "The potential slowing down of Nvidia's AI chip business and the company's ability to pivot to new technologies will have a significant impact on its long-term success. If Nvidia can successfully transition to new business verticals, it could maintain its dominant position in the market and continue to thrive. However, if it fails to adapt to changing conditions, it may experience stagnation or decline, as has been the case with other companies that have failed to evolve with technological advancements.\n",
       "\n",
       "## Link\n",
       "https://finance.yahoo.com/news/where-nvidia-stock-10-years-200000792.html\n",
       "\n",
       "# Nvidia's latest DLSS revision reduces VRAM usage by 20% for upscaling â€” optimizations reduce overhead of more powerful transformer model - Tom's Hardware\n",
       "## What is new?\n",
       "Nvidia has released a new revision of its DLSS (Deep Learning Super Sampling) technology, which reduces VRAM usage by 20% for upscaling. This update optimizes the transformer model, making it more efficient and reducing its memory footprint. The new revision, DLSS 310.3.0, improves the transformer model's VRAM usage, bringing it closer to the older CNN model's memory impact.\n",
       "\n",
       "## Highlight\n",
       "The key points of this update include:\n",
       "* 20% reduction in VRAM usage for upscaling\n",
       "* Optimizations reduce the overhead of the more powerful transformer model\n",
       "* The new transformer model consumes 40% more memory than the CNN model, down from nearly twice as much\n",
       "* Memory consumption increases linearly with resolution, with the transformer model consuming 85.77MB of VRAM at 1080p and 307.37MB at 4K\n",
       "\n",
       "## Why it matters\n",
       "This update is significant because it shows Nvidia's commitment to improving the efficiency of its DLSS technology. While the 20% reduction in VRAM usage may not have a noticeable impact on real-world applications, it demonstrates the company's efforts to optimize its technology for better performance. Additionally, the reduction in memory footprint could be beneficial for systems with limited VRAM, particularly at higher resolutions like 8K. This update also highlights the ongoing development and refinement of DLSS, which is now used in over 760 games and apps.\n",
       "\n",
       "## Link\n",
       "https://www.tomshardware.com/pc-components/gpus/nvidias-latest-dlss-revision-reduces-vram-usage-by-20-percent-for-upscaling-optimizations-reduce-overhead-of-more-powerful-transformer-model\n",
       "\n",
       "# Nvidia executives cash out $1bn worth of shares - Financial Times\n",
       "## What is new?\n",
       "Nvidia executives have recently sold a substantial amount of shares, totaling $1 billion in value. This significant transaction has drawn attention to the company's internal dynamics and potential future directions.\n",
       "\n",
       "## Highlight\n",
       "The key points of this news include the large-scale sale of Nvidia shares by its executives, amounting to $1 billion. This move could indicate a shift in the executives' confidence in the company's future prospects or a strategic decision to diversify their personal investments.\n",
       "\n",
       "## Why it matters\n",
       "The sale of such a large volume of shares by Nvidia executives could have implications for investor confidence and the company's stock price. It may also signal potential changes in Nvidia's leadership or strategy, as significant insider transactions often attract scrutiny from investors and market analysts. Understanding the motivations behind this sale can provide insights into the company's future growth prospects and industry trends.\n",
       "\n",
       "## Link\n",
       "https://www.ft.com/content/36f346ad-c649-42ac-a6b6-1a8cc881e0bb\n",
       "\n",
       "# Nvidia: The Music Is About To Stop (NASDAQ:NVDA) - Seeking Alpha\n",
       "## What is new?\n",
       "The article discusses the potential risks and challenges facing Nvidia Corporation, including macro and geopolitical risks, rising competition, and their potential impact on the company's performance. The authors, Bears of Wall Street, maintain a bearish stance on NVDA stock, citing these factors as reasons to sell.\n",
       "\n",
       "## Highlight\n",
       "The key points of the article include:\n",
       "* Nvidia's stock has risen around 15% since the last coverage before its Q1 earnings report\n",
       "* Macro and geopolitical risks could have a significant impact on Nvidia's performance\n",
       "* Rising competition may lead to lower demand for Nvidia's products in the future\n",
       "* The authors recommend a \"Sell\" position on NVDA stock due to these and other factors\n",
       "\n",
       "## Why it matters\n",
       "The article's analysis matters because it highlights the potential risks and challenges that Nvidia faces, which could impact the company's future growth and profitability. Investors who are considering buying or holding NVDA stock should be aware of these risks and consider the authors' bearish stance when making their investment decisions. Additionally, the article's focus on macro and geopolitical risks, as well as rising competition, underscores the importance of considering broader market trends and industry dynamics when evaluating individual stocks.\n",
       "\n",
       "## Link\n",
       "https://seekingalpha.com/article/4797785-nvidia-the-music-is-about-to-stop"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(message.artifact))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
